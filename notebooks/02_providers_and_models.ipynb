{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Lesson 2: LLM Providers & Models\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harshit-vibes/lyzr-adk-demo/blob/master/notebooks/02_providers_and_models.ipynb)\n",
    "\n",
    "\n",
    "üü¢ Beginner ¬∑ ‚è± 20 min\n",
    "\n",
    "lyzr-adk lets you switch between AI providers ‚Äî OpenAI, Anthropic, Google, Groq, Perplexity, and AWS Bedrock ‚Äî with a single string. This lesson shows you how to create agents backed by different LLMs and swap providers on an existing agent without recreating it.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Understand the `provider/model-name` string format\n",
    "- Create agents with different LLM providers\n",
    "- Compare responses from two providers side by side\n",
    "- Switch providers on an existing agent using `agent.update()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- **Lesson 1 completed** ‚Äî you should already know how to create an agent and call `agent.run()`\n",
    "- `LYZR_API_KEY` environment variable set (or ready to paste your key below)\n",
    "- API keys for any additional providers you want to test (e.g. `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`) ‚Äî the Lyzr platform routes calls through your own provider keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lyzr-adk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lyzr import Studio\n",
    "\n",
    "API_KEY = os.getenv(\"LYZR_API_KEY\", \"YOUR_LYZR_API_KEY\")\n",
    "studio = Studio(api_key=API_KEY)\n",
    "print(\"Studio ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## The Provider String Format\n",
    "\n",
    "Every agent in lyzr-adk is backed by a specific LLM. You specify the LLM using a **provider string** in the format:\n",
    "\n",
    "```\n",
    "\"provider/model-name\"\n",
    "```\n",
    "\n",
    "The part before the `/` is the **provider** (the company or platform hosting the model). The part after is the **model name** exactly as that provider refers to it.\n",
    "\n",
    "Here are all the providers supported in lyzr-adk:\n",
    "\n",
    "| Provider | String | Notes |\n",
    "|----------|--------|-------|\n",
    "| OpenAI | `openai/gpt-4o` | Default, versatile, great all-rounder |\n",
    "| Anthropic | `anthropic/claude-sonnet-4-5` | Strong reasoning and instruction-following |\n",
    "| Google | `google/gemini-2.0-flash` | Fast, multimodal (text + images) |\n",
    "| Groq | `groq/llama-3.3-70b` | Very fast inference via Groq hardware |\n",
    "| Perplexity | `perplexity/sonar-pro` | Web-grounded ‚Äî can cite live sources |\n",
    "| AWS Bedrock | `bedrock/amazon.nova-pro-v1:0` | Enterprise deployments on AWS |\n",
    "\n",
    "> **Note:** You only need an API key for the provider you are actually calling. If you only have an OpenAI key, you can only use `openai/...` models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All supported providers in lyzr-adk\n",
    "PROVIDERS = {\n",
    "    \"OpenAI\":      \"openai/gpt-4o\",\n",
    "    \"Anthropic\":   \"anthropic/claude-sonnet-4-5\",\n",
    "    \"Google\":      \"google/gemini-2.0-flash\",\n",
    "    \"Groq\":        \"groq/llama-3.3-70b\",\n",
    "    \"Perplexity\":  \"perplexity/sonar-pro\",\n",
    "}\n",
    "\n",
    "print(\"Supported provider strings:\")\n",
    "for name, provider_string in PROVIDERS.items():\n",
    "    print(f\"  {name:12} ‚Üí {provider_string}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Creating Agents with Different Providers\n",
    "\n",
    "The code to create an agent is identical regardless of provider ‚Äî the only thing that changes is the `provider` argument. This makes it easy to experiment with different LLMs without restructuring your code.\n",
    "\n",
    "In the example below, we create two agents with the same role, goal, and instructions, but backed by different models. This is the cleanest way to set up a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two agents with different providers\n",
    "openai_agent = studio.create_agent(\n",
    "    name=\"OpenAI Agent\",\n",
    "    provider=\"openai/gpt-4o\",\n",
    "    role=\"Helpful assistant\",\n",
    "    goal=\"Answer questions concisely\",\n",
    "    instructions=\"Keep responses to 1-2 sentences.\"\n",
    ")\n",
    "\n",
    "google_agent = studio.create_agent(\n",
    "    name=\"Google Agent\",\n",
    "    provider=\"google/gemini-2.0-flash\",\n",
    "    role=\"Helpful assistant\",\n",
    "    goal=\"Answer questions concisely\",\n",
    "    instructions=\"Keep responses to 1-2 sentences.\"\n",
    ")\n",
    "\n",
    "print(f\"OpenAI agent:  {openai_agent.id}\")\n",
    "print(f\"Google agent:  {google_agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Comparing Responses\n",
    "\n",
    "Because each model has been trained differently, they often produce distinct phrasings, levels of detail, and stylistic choices ‚Äî even for simple factual questions. Asking both agents the same question and printing the results side by side is the quickest way to feel those differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"In one sentence, what is machine learning?\"\n",
    "\n",
    "openai_response = openai_agent.run(question)\n",
    "google_response = google_agent.run(question)\n",
    "\n",
    "print(f\"OpenAI:  {openai_response.response}\")\n",
    "print(f\"\")\n",
    "print(f\"Google:  {google_response.response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Switching Provider on an Existing Agent\n",
    "\n",
    "You don't need to create a brand-new agent to change the underlying model. Call `agent.update(provider=...)` to swap the LLM in place ‚Äî the agent ID, role, goal, and instructions all stay the same.\n",
    "\n",
    "This is useful when you want to:\n",
    "- A/B test different models in production without changing agent IDs\n",
    "- Upgrade to a newer model version without reconfiguring everything\n",
    "- Fall back to a cheaper or faster model when latency matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before update: openai_agent uses OpenAI\")\n",
    "openai_agent.update(provider=\"anthropic/claude-sonnet-4-5\")\n",
    "print(f\"After update: openai_agent now uses Anthropic\")\n",
    "\n",
    "response = openai_agent.run(\"What is 2 + 2? One sentence only.\")\n",
    "print(f\"Response: {response.response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Common Mistake: Invalid Provider String Format\n",
    "\n",
    "The provider string **must** follow the `provider/model-name` pattern exactly. A common mistake is passing just the model name without the provider prefix ‚Äî for example, `\"gpt-4o\"` instead of `\"openai/gpt-4o\"`.\n",
    "\n",
    "lyzr-adk validates the format when you create or update an agent. If the string is invalid or references a model that doesn't exist, you'll get an error immediately rather than at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Common mistake: wrong format or non-existent model\n",
    "try:\n",
    "    bad_agent = studio.create_agent(\n",
    "        name=\"Bad Agent\",\n",
    "        provider=\"gpt-4o\",       # ‚ùå Missing \"openai/\" prefix\n",
    "        role=\"Test\", goal=\"Test\", instructions=\"Test\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error (expected): {e}\")\n",
    "\n",
    "# ‚úÖ Correct format always: \"provider/model-name\"\n",
    "print(\"\\n‚úÖ Correct format: 'openai/gpt-4o', 'google/gemini-2.0-flash', etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Create two agents backed by **different providers** from the `PROVIDERS` dict above. Ask both the same question about space and print their responses side by side.\n",
    "\n",
    "**Acceptance criteria:**\n",
    "- Both agents use a different entry from `PROVIDERS`\n",
    "- Both agents have the same `role`, `goal`, and `instructions`\n",
    "- You print each response labeled with the provider name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Choose two different providers from PROVIDERS dict above\n",
    "agent_a = studio.create_agent(\n",
    "    name=...,\n",
    "    provider=...,   # e.g. PROVIDERS[\"OpenAI\"]\n",
    "    role=\"Trivia expert\",\n",
    "    goal=\"Share interesting facts\",\n",
    "    instructions=\"Give exactly one fun fact in one sentence.\"\n",
    ")\n",
    "\n",
    "agent_b = studio.create_agent(\n",
    "    name=...,\n",
    "    provider=...,   # Pick a different provider\n",
    "    role=\"Trivia expert\",\n",
    "    goal=\"Share interesting facts\",\n",
    "    instructions=\"Give exactly one fun fact in one sentence.\"\n",
    ")\n",
    "\n",
    "# TODO: Ask both the same question and print side by side\n",
    "question = \"Give me a fun fact about space.\"\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Provider | String | Best for |\n",
    "|----------|--------|----------|\n",
    "| OpenAI | `openai/gpt-4o` | General-purpose tasks, code, reasoning |\n",
    "| Anthropic | `anthropic/claude-sonnet-4-5` | Long documents, nuanced instruction-following |\n",
    "| Google | `google/gemini-2.0-flash` | Speed, multimodal inputs |\n",
    "| Groq | `groq/llama-3.3-70b` | Ultra-low latency inference |\n",
    "| Perplexity | `perplexity/sonar-pro` | Questions requiring up-to-date web data |\n",
    "| AWS Bedrock | `bedrock/amazon.nova-pro-v1:0` | Enterprise / AWS-native deployments |\n",
    "\n",
    "**Key takeaways:**\n",
    "- Provider strings always follow `\"provider/model-name\"` ‚Äî no exceptions\n",
    "- You only need an API key for the provider you actually call\n",
    "- Create agents with different providers: `studio.create_agent(..., provider=\"openai/gpt-4o\")`\n",
    "- Switch provider on an existing agent: `agent.update(provider=\"google/gemini-2.0-flash\")`\n",
    "- Switching provider does **not** change the agent ID, role, goal, or instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "‚û°Ô∏è **Lesson 3: Agent Lifecycle**\n",
    "\n",
    "Now that you can create agents with any provider, learn to manage them over time ‚Äî list all your agents, retrieve one by ID, clone an existing agent into a new one, and delete agents you no longer need."
   ]
  }
 ]
}