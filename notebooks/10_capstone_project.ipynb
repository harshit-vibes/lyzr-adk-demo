{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
   "metadata": {},
   "source": [
    "# Lesson 10: Capstone — Research Intelligence Agent\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harshit-vibes/lyzr-adk-demo/blob/master/notebooks/10_capstone_project.ipynb)\n",
    "\n",
    "\n",
    "![Advanced](https://img.shields.io/badge/Level-Advanced-red) ![Duration](https://img.shields.io/badge/Duration-45%20min-blue)\n",
    "\n",
    "**Series:** lyzr-adk in 10 Lessons | **Lesson:** 10 of 10\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "You've learned all the building blocks. Now we put them all together.\n",
    "\n",
    "In this capstone, you'll build a **Research Intelligence Agent** — a production-grade assistant that combines RAG, memory, tools, structured outputs, dynamic contexts, and RAI guardrails into a single, powerful agent.\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Build\n",
    "\n",
    "The **Research Intelligence Agent** is a senior AI analyst that:\n",
    "\n",
    "- Draws on a **knowledge base** of market research documents (RAG) to ground its answers in real data\n",
    "- Uses **custom tools** — a web search stub and a citation formatter — to gather and format information\n",
    "- Maintains **conversation memory** across a multi-turn research session so every follow-up builds on prior context\n",
    "- Adapts its behavior using **dynamic contexts** — it knows the current project name, client, deadline, and the researcher's preferred report style\n",
    "- Enforces **RAI guardrails** to detect toxicity, block prompt injection attacks, and redact PII before it ever reaches the LLM\n",
    "- Produces a final **structured output** in the form of a `ResearchReport` Pydantic model, with typed fields for `topic`, `executive_summary`, `key_findings`, `recommendations`, `confidence_score`, and `sources_used`\n",
    "\n",
    "By the end you'll have a working agent you could drop into a real enterprise workflow with minimal changes.\n",
    "\n",
    "---\n",
    "\n",
    "## Features Combined in This Lesson\n",
    "\n",
    "| Feature | Source Lesson |\n",
    "|---|---|\n",
    "| `Studio` + `create_agent` + `agent.run` | Lesson 1 |\n",
    "| Custom LLM provider (`openai/gpt-4o`) | Lesson 2 |\n",
    "| Agent lifecycle (create, inspect) | Lesson 3 |\n",
    "| Structured output (`ResearchReport`) | Lesson 4 |\n",
    "| Memory + multi-turn sessions | Lesson 5 |\n",
    "| Custom tools (`search_web`, `format_citation`) | Lesson 6 |\n",
    "| Knowledge base / RAG | Lesson 7 |\n",
    "| Dynamic contexts (project + profile) | Lesson 8 |\n",
    "| RAI guardrails (toxicity, PII, injection) | Lesson 9 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3d4e5-f6a7-8901-bcde-f12345678901",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "> **All Lessons 1–9 must be completed before running this notebook.**\n",
    "\n",
    "This capstone assumes you are comfortable with every concept introduced in the series:\n",
    "\n",
    "- **Lesson 1** — Connecting to Lyzr Studio and running your first agent\n",
    "- **Lesson 2** — Choosing LLM providers and models (OpenAI, Anthropic, Google, etc.)\n",
    "- **Lesson 3** — The full agent lifecycle: create, list, get, update, delete\n",
    "- **Lesson 4** — Returning structured data with Pydantic and `response_format`\n",
    "- **Lesson 5** — Conversation memory and persistent multi-turn sessions with `session_id`\n",
    "- **Lesson 6** — Registering Python functions as callable tools with `agent.add_tool`\n",
    "- **Lesson 7** — Building knowledge bases and enabling RAG with `knowledge_base_ids`\n",
    "- **Lesson 8** — Injecting dynamic runtime context with `studio.create_context`\n",
    "- **Lesson 9** — Configuring Responsible AI policies for safety and compliance\n",
    "\n",
    "You'll also need:\n",
    "- A valid `LYZR_API_KEY` set as an environment variable (or pasted directly below)\n",
    "- The `lyzr-adk` and `pydantic` packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6-a7b8-9012-cdef-123456789012",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lyzr-adk[jupyter] -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7-b8c9-0123-defa-234567890123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "from lyzr import Studio\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "API_KEY = os.getenv(\"LYZR_API_KEY\", \"YOUR_LYZR_API_KEY\")\n",
    "studio = Studio(api_key=API_KEY)\n",
    "\n",
    "print(\"All imports ready! Let's build our Research Intelligence Agent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8-c9d0-1234-efab-345678901234",
   "metadata": {},
   "source": [
    "## Step 1: Define the Research Report Schema\n",
    "\n",
    "Before we build the agent, we define what we want back from it.\n",
    "\n",
    "By passing a Pydantic model as `response_format`, lyzr-adk instructs the LLM to return a JSON object that exactly matches the schema. The SDK then parses and validates the response, so `report_response.response` is a fully typed `ResearchReport` instance — not a raw string.\n",
    "\n",
    "Our schema captures everything a strategy team needs in an executive research brief:\n",
    "\n",
    "| Field | Type | Description |\n",
    "|---|---|---|\n",
    "| `topic` | `str` | The research topic analyzed |\n",
    "| `executive_summary` | `str` | 2–3 sentence high-level summary |\n",
    "| `key_findings` | `List[str]` | 5–7 specific, evidence-based findings |\n",
    "| `recommendations` | `List[str]` | 3–5 actionable recommendations |\n",
    "| `confidence_score` | `float` | Agent's confidence in the findings (0.0–1.0) |\n",
    "| `sources_used` | `List[str]` | Sources and references cited |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9-d0e1-2345-fabc-456789012345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchReport(BaseModel):\n",
    "    topic: str = Field(description=\"The research topic analyzed\")\n",
    "    executive_summary: str = Field(description=\"2-3 sentence high-level summary for executives\")\n",
    "    key_findings: List[str] = Field(description=\"5-7 specific, evidence-based findings\")\n",
    "    recommendations: List[str] = Field(description=\"3-5 actionable recommendations\")\n",
    "    confidence_score: float = Field(ge=0.0, le=1.0, description=\"Confidence in findings from 0.0 to 1.0\")\n",
    "    sources_used: List[str] = Field(description=\"List of sources/references cited\")\n",
    "\n",
    "print(\"ResearchReport schema defined\")\n",
    "print(f\"   Fields: {list(ResearchReport.model_fields.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0-e1f2-3456-abcd-567890123456",
   "metadata": {},
   "source": [
    "## Step 2: Build the Knowledge Base\n",
    "\n",
    "Our agent needs background material to reason from — a foundation of facts it can cite in its report.\n",
    "\n",
    "We create a **knowledge base** and load it with a market overview document covering:\n",
    "- Key AI agent frameworks and their positioning\n",
    "- Adoption statistics and market trends\n",
    "- Enterprise usage patterns and top use cases\n",
    "\n",
    "When the agent runs, lyzr-adk performs a **RAG retrieval** — it finds the most relevant passages from this KB and injects them into the LLM's context automatically, grounding the agent's answers in real data rather than hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1-f2a3-4567-bcde-678901234567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the research knowledge base\n",
    "kb = studio.create_knowledge_base(name=\"ai_trends_research_kb\")\n",
    "print(f\"Knowledge base created: {kb.id}\")\n",
    "\n",
    "# Add background research content\n",
    "research_background = \"\"\"\n",
    "# AI Agent Frameworks — Market Overview 2026\n",
    "\n",
    "## Key Players\n",
    "- **Lyzr ADK**: Enterprise-focused, production-ready, supports 20+ models. Key features: RAG, memory, tools, RAI guardrails.\n",
    "- **LangChain**: Open-source framework with large ecosystem. Complex setup, flexible.\n",
    "- **AutoGen**: Microsoft's multi-agent framework. Strong for agentic workflows.\n",
    "- **CrewAI**: Role-based multi-agent system. Good for team simulations.\n",
    "\n",
    "## Market Trends\n",
    "1. RAG adoption is up 340% year-over-year as enterprises ground LLMs in private data.\n",
    "2. Safety-first development: 78% of enterprise buyers require built-in guardrails.\n",
    "3. Multi-model flexibility: teams want to switch between OpenAI, Anthropic, and Google.\n",
    "4. Memory and sessions: persistent agents outperform stateless agents in user satisfaction (3.2x).\n",
    "5. Tool calling is now standard: 94% of production agents use at least one external tool.\n",
    "\n",
    "## Enterprise Adoption\n",
    "- 62% of Fortune 500 companies are piloting AI agents in 2026.\n",
    "- Average production agent uses 3.4 tools and 1.2 knowledge bases.\n",
    "- Top use cases: customer support (34%), internal Q&A (28%), data analysis (19%).\n",
    "\"\"\"\n",
    "\n",
    "kb.add_text(text=research_background, source=\"ai-market-report-2026\")\n",
    "print(\"Background research added to KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2-a3b4-5678-cdef-789012345678",
   "metadata": {},
   "source": [
    "## Step 3: Define Research Tools\n",
    "\n",
    "Our agent needs two tools:\n",
    "\n",
    "1. **`search_web`** — simulates a live web search for current market data. In a real deployment you'd call the Tavily, SerpAPI, or Bing Search API here. The agent calls this tool autonomously when it determines it needs fresh information.\n",
    "\n",
    "2. **`format_citation`** — takes a source name and a short description and returns a consistently formatted citation string. This ensures every source in `sources_used` follows the same format regardless of which turn the agent found it in.\n",
    "\n",
    "Key point: the **docstring is the tool's description** for the LLM. Write it clearly — the model reads the docstring to decide when and how to call the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3-b4c5-6789-defa-890123456789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for the latest information, news, and data on a given topic.\n",
    "\n",
    "    Returns relevant search results including titles, snippets, and sources.\n",
    "    Use this when you need current information beyond your training data.\n",
    "    \"\"\"\n",
    "    # Simulated search results (in production, call a real search API)\n",
    "    simulated_results = {\n",
    "        \"ai agent frameworks\": (\n",
    "            \"Result: Top frameworks in 2026 include Lyzr ADK, LangChain, AutoGen, CrewAI. \"\n",
    "            \"Lyzr leads in enterprise adoption due to built-in safety features.\"\n",
    "        ),\n",
    "        \"rag adoption rate\": (\n",
    "            \"Result: RAG adoption grew 340% in 2025-2026. \"\n",
    "            \"71% of enterprises now use RAG for internal knowledge management.\"\n",
    "        ),\n",
    "        \"default\": (\n",
    "            f\"Result: Found recent articles and reports about '{query}'. \"\n",
    "            \"Multiple authoritative sources confirm growing interest in this area.\"\n",
    "        ),\n",
    "    }\n",
    "    query_lower = query.lower()\n",
    "    for key in simulated_results:\n",
    "        if key in query_lower:\n",
    "            return simulated_results[key]\n",
    "    return simulated_results[\"default\"]\n",
    "\n",
    "\n",
    "def format_citation(source_name: str, description: str) -> str:\n",
    "    \"\"\"Format a source name and description into a properly formatted citation for a research report.\n",
    "\n",
    "    Use this when compiling the sources_used list in the final report.\n",
    "    \"\"\"\n",
    "    return f\"[{source_name}]: {description}\"\n",
    "\n",
    "\n",
    "print(\"Tools defined: search_web, format_citation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4-c5d6-7890-efab-901234567890",
   "metadata": {},
   "source": [
    "## Step 4: Configure Safety Guardrails\n",
    "\n",
    "Production agents handle real user input — and real user input can be malicious, sensitive, or toxic. We attach a **Responsible AI policy** to guard against three threat vectors:\n",
    "\n",
    "| Guardrail | Setting | Effect |\n",
    "|---|---|---|\n",
    "| Toxicity | `True` | Blocks requests containing harmful or abusive content |\n",
    "| Prompt injection | `True` | Detects attempts to hijack the agent's instructions |\n",
    "| PII | `\"redact\"` | Strips names, emails, phone numbers, etc. before they reach the LLM |\n",
    "\n",
    "The policy is enforced at the platform level on every `agent.run` call — no extra code required at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5-d6e7-8901-fabc-012345678901",
   "metadata": {},
   "outputs": [],
   "source": [
    "rai_policy = studio.create_rai_policy(\n",
    "    name=\"Research Agent Safety\",\n",
    "    toxicity=True,\n",
    "    prompt_injection=True,\n",
    "    pii=\"redact\"   # Redact any PII from research queries before the LLM sees them\n",
    ")\n",
    "print(f\"RAI policy created: {rai_policy.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6-e7f8-9012-abcd-123456789012",
   "metadata": {},
   "source": [
    "## Step 5: Set Up Dynamic Contexts\n",
    "\n",
    "Contexts let us inject runtime information into the agent's system prompt without hardcoding it.\n",
    "\n",
    "We create two contexts:\n",
    "\n",
    "**`research_project`** — tells the agent what project it's working on, who the client is, and when the deliverable is due. This shapes the report's tone and scope.\n",
    "\n",
    "**`researcher_profile`** — tells the agent the preferences of the human who'll receive the output: their expertise level, preferred report style, and citation format. This makes the output feel tailored rather than generic.\n",
    "\n",
    "In a real deployment, these values would be fetched dynamically from a database or user session on each call — the agent always has fresh context without any code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7-f8a9-0123-bcde-234567890123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current research project context\n",
    "project_ctx = studio.create_context(\n",
    "    name=\"research_project\",\n",
    "    value=(\n",
    "        \"Project: AI Agent Framework Analysis 2026 | \"\n",
    "        \"Client: TechCorp Strategy Team | \"\n",
    "        \"Deadline: End of Q1 2026 | \"\n",
    "        \"Deliverable: Executive research report\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Researcher profile context\n",
    "user_ctx = studio.create_context(\n",
    "    name=\"researcher_profile\",\n",
    "    value=(\n",
    "        \"Researcher: Senior AI Analyst | \"\n",
    "        \"Expertise: Enterprise software, AI/ML | \"\n",
    "        \"Report style: Concise, data-driven, executive-friendly | \"\n",
    "        \"Citation style: APA\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Contexts created:\")\n",
    "print(f\"   Project: {project_ctx.id}\")\n",
    "print(f\"   Profile: {user_ctx.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8-a9b0-1234-cdef-345678901234",
   "metadata": {},
   "source": [
    "## Step 6: Assemble the Agent\n",
    "\n",
    "This is where everything comes together.\n",
    "\n",
    "We call `studio.create_agent` with a provider, role, goal, and instructions, then chain on all the features we've prepared. The order of the `.add_*` calls doesn't matter — lyzr-adk assembles the full agent configuration before the first `run`.\n",
    "\n",
    "```\n",
    "create_agent         → identity, LLM, role, goal, instructions, KB\n",
    "  .add_tool          → search_web\n",
    "  .add_tool          → format_citation\n",
    "  .add_memory        → 15-message sliding window\n",
    "  .add_context       → project details\n",
    "  .add_context       → researcher profile\n",
    "  .add_rai_policy    → toxicity + injection + PII redaction\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9-b0c1-2345-defa-456789012345",
   "metadata": {},
   "outputs": [],
   "source": "research_agent = studio.create_agent(\n    name=\"Research Intelligence Agent\",\n    provider=\"openai/gpt-4o\",\n    role=\"Senior AI research analyst with expertise in enterprise technology\",\n    goal=\"Produce comprehensive, accurate, actionable research reports grounded in evidence\",\n    instructions=(\n        \"You are a senior research analyst. Your reports are data-driven and concise. \"\n        \"Always use the search_web tool to find current information. \"\n        \"Always use the knowledge base context when available. \"\n        \"Format citations using the format_citation tool. \"\n        \"When generating reports, be specific and include real statistics. \"\n        \"Match the researcher's preferred style from the profile context.\"\n    ),\n    knowledge_base_ids=[kb.id],\n    response_model=ResearchReport   # structured output set at creation time\n)\n\n# Add all features\nresearch_agent.add_tool(search_web)\nresearch_agent.add_tool(format_citation)\nresearch_agent.add_memory(max_messages=15)\nresearch_agent.add_context(project_ctx)\nresearch_agent.add_context(user_ctx)\nresearch_agent.add_rai_policy(rai_policy)\n\nprint(\"Research Intelligence Agent assembled!\")\nprint(f\"   Agent ID: {research_agent.id}\")\nprint()\nprint(\"Features enabled:\")\nprint(\"  Knowledge base (RAG)\")\nprint(\"  Tools (search_web, format_citation)\")\nprint(\"  Memory (15 messages)\")\nprint(\"  Contexts (project + profile)\")\nprint(\"  RAI guardrails (toxicity, PII, injection)\")\nprint(\"  Structured output (ResearchReport)\")"
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0-c1d2-3456-efab-567890123456",
   "metadata": {},
   "source": [
    "## Step 7: Run the Research Session\n",
    "\n",
    "We drive the agent through a **multi-turn research workflow** using a shared `session_id`.\n",
    "\n",
    "Each turn builds on the last:\n",
    "1. **Turn 1 — Scope:** Define the research question and identify frameworks to analyze\n",
    "2. **Turn 2 — Data gathering:** Trigger the web search tool for live market data\n",
    "3. **Turn 3 — Report generation:** Synthesize everything into a structured `ResearchReport`\n",
    "\n",
    "Because memory is enabled, the agent remembers what it said in Turn 1 when answering Turn 2, and has the full conversation history when composing the final report in Turn 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1-d2e3-4567-fabc-678901234567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a research session\n",
    "session_id = str(uuid.uuid4())\n",
    "print(f\"Research session started: {session_id}\\n\")\n",
    "\n",
    "# Turn 1: Scope the research\n",
    "r1 = research_agent.run(\n",
    "    \"I need to research AI agent frameworks for our enterprise strategy report. \"\n",
    "    \"What are the key frameworks we should analyze?\",\n",
    "    session_id=session_id\n",
    ")\n",
    "print(f\"Turn 1 — Scoping:\\n{r1.response}\\n\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2-e3f4-5678-abcd-789012345678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 2: Deep dive with the web search tool\n",
    "r2 = research_agent.run(\n",
    "    \"Search for the latest adoption rates and market trends for AI agent frameworks in enterprise.\",\n",
    "    session_id=session_id\n",
    ")\n",
    "print(f\"Turn 2 — Market data:\\n{r2.response}\\n\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3-f4a5-6789-bcde-890123456789",
   "metadata": {},
   "outputs": [],
   "source": "# Turn 3: Generate the final structured report\n# response_model=ResearchReport was set on the agent, so run() returns ResearchReport directly\nprint(\"Generating structured research report...\\n\")\n\nreport: ResearchReport = research_agent.run(\n    \"Based on our research session, generate a comprehensive research report for the TechCorp strategy team.\",\n    session_id=session_id\n)\n\n# Display the report\nprint(\"=\" * 60)\nprint(\"RESEARCH REPORT\")\nprint(\"=\" * 60)\nprint(f\"\\nTopic: {report.topic}\")\nprint(f\"\\nExecutive Summary:\\n{report.executive_summary}\")\nprint(f\"\\nKey Findings:\")\nfor i, finding in enumerate(report.key_findings, 1):\n    print(f\"   {i}. {finding}\")\nprint(f\"\\nRecommendations:\")\nfor i, rec in enumerate(report.recommendations, 1):\n    print(f\"   {i}. {rec}\")\nprint(f\"\\nConfidence Score: {report.confidence_score:.1%}\")\nprint(f\"\\nSources Used:\")\nfor source in report.sources_used:\n    print(f\"   - {source}\")"
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4-a5b6-7890-cdef-901234567890",
   "metadata": {},
   "source": [
    "## What We Built\n",
    "\n",
    "Here's every feature used in this capstone and where it came from:\n",
    "\n",
    "| Feature | API call | Lesson |\n",
    "|---|---|---|\n",
    "| Studio client | `Studio(api_key=...)` | 1 |\n",
    "| Custom LLM provider | `provider=\"openai/gpt-4o\"` | 2 |\n",
    "| Agent creation | `studio.create_agent(...)` | 1, 3 |\n",
    "| Knowledge base | `studio.create_knowledge_base()` + `kb.add_text()` | 7 |\n",
    "| RAG retrieval | `knowledge_base_ids=[kb.id]` | 7 |\n",
    "| Custom tools | `agent.add_tool(search_web)` | 6 |\n",
    "| Tool with side effect | `agent.add_tool(format_citation)` | 6 |\n",
    "| Conversation memory | `agent.add_memory(max_messages=15)` | 5 |\n",
    "| Multi-turn session | `session_id=session_id` on every `run` | 5 |\n",
    "| Dynamic project context | `studio.create_context(name=\"research_project\", ...)` | 8 |\n",
    "| Dynamic user context | `studio.create_context(name=\"researcher_profile\", ...)` | 8 |\n",
    "| RAI guardrails | `studio.create_rai_policy(toxicity=True, pii=\"redact\", ...)` | 9 |\n",
    "| Structured output | `response_format=ResearchReport` | 4 |\n",
    "| Typed response access | `report_response.response` as `ResearchReport` | 4 |\n",
    "\n",
    "Every one of these features works independently — and they compose cleanly because lyzr-adk was designed from the start for production use cases exactly like this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4a5-b6c7-8901-defa-012345678902",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You've completed all 10 lessons of **lyzr-adk in 10 Lessons**.\n",
    "\n",
    "Here's the full journey:\n",
    "\n",
    "```\n",
    "Lesson 1:  Studio + create_agent + agent.run\n",
    "Lesson 2:  Providers & models (20+ LLMs)\n",
    "Lesson 3:  Agent lifecycle (CRUD)\n",
    "Lesson 4:  Structured outputs (Pydantic)\n",
    "Lesson 5:  Memory & sessions\n",
    "Lesson 6:  Custom tools & functions\n",
    "Lesson 7:  RAG & knowledge bases\n",
    "Lesson 8:  Dynamic contexts\n",
    "Lesson 9:  Responsible AI guardrails\n",
    "Lesson 10: Capstone — all features combined\n",
    "```\n",
    "\n",
    "You now know how to build production-grade AI agents that are:\n",
    "- **Grounded** — RAG keeps answers anchored to real data\n",
    "- **Capable** — tools extend what the agent can do beyond the LLM alone\n",
    "- **Persistent** — memory makes sessions feel like a real conversation\n",
    "- **Adaptive** — contexts let the agent tailor itself to each user or project\n",
    "- **Safe** — RAI guardrails protect users and your organization\n",
    "- **Structured** — Pydantic outputs make agent responses programmable\n",
    "\n",
    "The Research Intelligence Agent you built today is not a demo — with a real search API key and your own knowledge base documents, it's deployable as-is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6-c7d8-9012-efab-123456789013",
   "metadata": {},
   "source": [
    "## Beyond This Series\n",
    "\n",
    "### Optional Advanced Lessons\n",
    "\n",
    "The series continues with three optional advanced lessons:\n",
    "\n",
    "- **Lesson 11: Streaming** — stream token-by-token responses for real-time UIs using `agent.stream`\n",
    "- **Lesson 12: Image & File Generation** — agents that produce images, PDFs, and structured files\n",
    "- **Lesson 13: Advanced Features** — webhooks, agent-to-agent calls, and deployment patterns\n",
    "\n",
    "### Deploy to Production\n",
    "\n",
    "- Full documentation: [docs.lyzr.ai](https://docs.lyzr.ai)\n",
    "- API reference, deployment guides, and integration examples\n",
    "\n",
    "### Community & Support\n",
    "\n",
    "- Join the community: [discord.gg/lyzr](https://discord.gg/lyzr)\n",
    "- Report issues, share agents, get help from the team and other builders\n",
    "\n",
    "### Package\n",
    "\n",
    "- PyPI: [pypi.org/project/lyzr-adk](https://pypi.org/project/lyzr-adk/)\n",
    "- `pip install lyzr-adk` — always installs the latest stable release\n",
    "\n",
    "---\n",
    "\n",
    "*Built with lyzr-adk — the fastest way to ship production AI agents.*"
   ]
  }
 ]
}